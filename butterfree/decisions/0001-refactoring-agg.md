# [Aggregation Refactoring]
Date: 2020-03-16

## Status: Open

# Abstract

ADR to discuss the refactoring of the class [AggregationTransform](https://github.com/quintoandar/butterfree/blob/staging/butterfree/core/transform/transformations/aggregated_transform.py) on the Butterfree project.

# Context

AggregatedTransform is becoming a big class that does everything. We don’t want that. So let’s discuss a refactoring here.

# Proposal

AggregationTransform be simple, just with the methods: output column and transform, and we implement a .with_ as the [Reader](https://github.com/quintoandar/butterfree/blob/57fc4c5b7c4f2c9cc2c44961a6577d57980fd9d5/butterfree/core/extract/readers/reader.py#L26), which we can call aggregations with or without windows/groupby.

## AggregationTransform

```python
from typing import List
from parameters_validation import non_blank
from pyspark.sql import DataFrame
from butterfree.core.transform.transformations.transform_component import (
    TransformComponent,
)
class AggregatedTransform(TransformComponent):
    def __init__(
        self,
        mode: str,
        aggregations: non_blank(List[str]),
        windows: List[str],
        groupby: List[str],
    ):
        super().__init__()
        self.mode = mode
        self.aggregations = aggregations
        self.windows = windows
        self.groupby = grouby

    @property
    def output_columns(self) -> List[str]:
        """Columns generated by the transformation."""
        output_columns = []
        for aggregation in self._aggregations:
            if windows:
                for window in self._windows:
                    output_columns.append(
                        f"{self._parent.name}__{aggregation}_over_"
                        f"{str(window.split()[1])}_{window.split()[0]}_{self.mode[0]}
                    )
            else:
                output_columns.append(
                    f"{self._parent.name}__{aggregation}"}
                )

        return output_columns

    def transform(self, dataframe: DataFrame) -> DataFrame:
        """Performs a transformation to the feature pipeline.

        Args:
            dataframe: input dataframe.

        Returns:
            Transformed dataframe.

        """
        for aggregation in self.aggregations:
            if windows:
                for window in self._windows:
                    dataframe = dataframe.withColumn(
                        f"{self._parent.name}__{aggregation}_over_"
                        f"{str(window.split()[1])}_{window.split()[0]}_{self.mode[0]},
                        agg_method(aggregation, windows, groupby, mode),
                    )
            else:
                dataframe = dataframe.withColumn(
                    f"{self._parent.name}__{aggregation}",
                    agg_method(aggregation, windows, groupby, mode),
                )
        return dataframe
```

## TransformComponent

[...]
```python
 def with_(self, transformer: Callable, *args, **kwargs):
        """Define a new transformation for the Reader.

        All the transformations are used when the method consume is called.

        Args:
            transformer: method that receives a dataframe and output a
                dataframe.
            *args: args for the transformer.
            **kwargs: kwargs for the transformer.

        Returns:
            Reader object with new transformation

        """
        new_transformation = {
            "transformer": transformer,
            "args": args if args else (),
            "kwargs": kwargs if kwargs else {},
        }
        self.transformations.append(new_transformation)
        return self
```
[...]

## Aggregation Methods
In transform module, we can create a python folder "agregations" with:

- Constants: Aggregations types, supported time windows;
- GroupBy method
- Windows methods
- Aggregation simple method

### Constants Example
```python
"""Aggregation Type Enum Entity."""

from enum import Enum
from pyspark.sql import functions

class AggregationType(Enum):
    """Holds constants for aggregation types within AggregationTransform."""

    AVG = functions.avg
    STDDEV_POP = functions.stddev_pop
    COUNT = functions.count
    COLLECT_SET = functions.collect_set
```

# Decision

TBD