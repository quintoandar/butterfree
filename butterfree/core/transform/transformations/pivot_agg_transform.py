"""Pivot Aggregated Transform entity."""

from typing import List

from parameters_validation import non_blank, non_null
from pyspark.sql import DataFrame, functions

from butterfree.core.constants.aggregations_type import ALLOWED_AGGREGATIONS
from butterfree.core.extract.pre_processing import forward_fill
from butterfree.core.transform.transformations.transform_component import (
    TransformComponent,
)


class PivotAggTransform(TransformComponent):
    """Defines a Pivot Aggregated transformation.

    Attributes:
        dataframe: dataframe to be pivoted.
        group_by_columns: list of columns' names to be grouped.
        pivot_column: column to be pivoted.
        agg_column: column to be aggregated by pivoted category.
        aggregation: desired spark aggregation function to be performed.
            An example: spark_agg(col_name). See docs for all spark_agg:
            https://spark.apache.org/docs/2.3.1/api/python/_modules/pyspark/sql/functions.html
        mock_value: value used to make a difference between true nulls resulting from
            the aggregation and empty values from the pivot transformation.
        mock_type: mock_value data type (compatible with spark).
        with_forward_fill: applies a forward fill to null values after the pivot
            operation.
    """

    def __init__(
        self,
        group_by_columns: non_blank(List[str]),
        pivot_column: non_blank(str),
        agg_column: non_blank(str),
        aggregations: non_blank(List[str]),
        mock_value: non_null(object) = None,
        mock_type: non_null(object) = None,
        with_forward_fill: non_null(bool) = False,
    ):
        super().__init__()
        self.group_by_columns = group_by_columns
        self.pivot_column = pivot_column
        self.agg_column = agg_column
        self.aggregations = aggregations
        self.mock_value = mock_value
        self.mock_type = mock_type
        self.with_forward_fill = with_forward_fill

    @property
    def output_columns(self) -> List[str]:
        """Columns generated by the transformation."""
        output_columns = []
        for aggregation in self.aggregations:
            output_columns.append(f"{self._parent.name}__{aggregation}")

        return output_columns

    def transform(self, dataframe: DataFrame) -> DataFrame:
        """Performs a transformation to the feature pipeline.

        Args:
            dataframe: input dataframe.

        Returns:
            Transformed dataframe.

        """
        agg_column_type = None
        if self.mock_value is not None:
            if self.mock_type is None:
                raise AttributeError(
                    "When proving a mock value, users must inform the data type,"
                    " which should be supported by Spark."
                )
            agg_column_type = dict(dataframe.dtypes).get(self.agg_column)
            dataframe = dataframe.withColumn(
                self.agg_column, functions.col(self.agg_column).cast(self.mock_type)
            ).fillna({self.agg_column: self.mock_value})

        pivoted = (
            dataframe.groupBy(*self.group_by_columns)
            .pivot(self.pivot_column)
            .agg(
                *[
                    ALLOWED_AGGREGATIONS[aggregation](self.agg_column).alias(
                        aggregation
                    )
                    for aggregation in self.aggregations
                ]
            )
        )

        new_columns = [c for c in pivoted.columns if c not in self.group_by_columns]

        if self.with_forward_fill:
            for c in new_columns:
                pivoted = forward_fill(
                    dataframe=pivoted,
                    partition_by=self.group_by_columns[:-1],
                    order_by=self.group_by_columns[-1],
                    fill_column=c,
                )

        if self.mock_value is not None:
            for c in new_columns:
                pivoted = pivoted.withColumn(
                    c,
                    functions.when(
                        functions.col(c) != self.mock_value, functions.col(c)
                    ).cast(agg_column_type),
                )

        if len(self.aggregations) == 1:
            for aggregation in self.aggregations:
                for column in pivoted.columns:
                    if column not in self.group_by_columns:
                        pivoted = pivoted.withColumnRenamed(
                            column, f"{column}__{aggregation}"
                        )

        return pivoted
